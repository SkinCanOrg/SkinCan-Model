{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skincan-models-v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+8j7p/V1PdDE8nZBdEHFD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fadlinisasiGit/SkinCan-model/blob/main/skincan_models_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Product-Based-Capstone-Project**\n",
        "\n",
        "**SkinCan Skin Cancer Detection App**\n",
        "\n",
        "Final Selected Themes : Human Healthcare & Animal Welfare\n",
        "\n",
        "Team Member :\n",
        "*   (ML) M7134F1606 - Muhammad Fadli Ramadhan - Politeknik Negeri Sriwijaya\n",
        "*   (ML) M2008F0851 - Adhitya Ghiffari Pramudito - Universitas Gadjah Mada\n",
        "*   (MD) A2191F1821 - Ahmad Ansori Palembani - Universitas Bina Darma\n",
        "*   (MD) A7191F1820 - Muhammad Fharid Akbar - Universitas Bina Darma\n",
        "*   (CC) C2322F2819 - Muhammad Mustafa Kamal - Universitas Syiah Kuala\n",
        "*   (CC) C7457F3068 - Wulan Ayu Rania Sari -Universitas Nahdlatul Ulama Lampung\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zIxXcEZlz3HF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Executive Summary :**\n",
        "\n",
        "At this time there are so many dangers that can lurk human health, even in this era of pandemic, maintaining health is very important for everyone. People should have awareness to maintain health, especially the health of the skin. Therefore, by utilizing machine learning, cloud computing to create a skin cancer detection application by identifying the input image to remind the public the importance of maintaining healthy skin. In this project, We have a problem formulation as follows:\n",
        "\n",
        "*   How to detect various skin cancers in humans through the application?\n",
        "*   How to treat skin cancer early?\n",
        "*   How accurately does this application detect skin cancer?\n",
        "\n",
        "Our team wants to solve this problem because we want someone who has the potential for cancer to avoid a more serious problem, so that users who use this application can take preventive measures to prevent this problem.\n",
        "\n",
        "**How did your team come up with this project?**\n",
        "\n",
        "We want to build an application that can help the public and health workers to detect skin diseases in humans, including skin cancer. This application uses Deep Learning algorithms to predict various skin diseases to achieve maximum accuracy in predicting skin diseases at an early stage. Feature extraction plays a key role in the classification of skin diseases. In addition, Explainable AI is used to interpret decisions made by our machine learning models. With this application, hopefully, it can help users to detect skin diseases early so they can take preventive measures.\n",
        "\n",
        "**Based on your knowledge and explorations, tell us the Machine Learning Part of your capstone?**\n",
        "\n",
        "In this project, weâ€™re using Python as main programming language, Tensorflow as mandatory library, Sckit-learn and keras as libraries, AI Platform as platform, TFLite as Tools for Model Deployment to Android, Kaggle as dataset resource, Google Colab as IDE, and create Machine Learning Model as main the feature in our app."
      ],
      "metadata": {
        "id": "Ocm-YF600oQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Collecting**"
      ],
      "metadata": {
        "id": "VS-OE0ia0wsu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2KadP35ySn9"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import itertools\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, BatchNormalization, Dropout, Dense, MaxPool2D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from IPython.display import display\n",
        "#To see the value of multiple statements at once.\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings # tf needs to learn to stfu\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
        "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "OgKpF4Zu15dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking tensorflow version\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "TuRA3mfG04AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install opendataset packages\n",
        "!pip install opendatasets\n",
        "\n",
        "# download plotly package\n",
        "!pip install plotly"
      ],
      "metadata": {
        "id": "2aUijBUp044q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install paket kaggle\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload file kaggle.json dari Create New API Token Akun Kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "V-P7WcEC06tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Dataset from Kaggle\n",
        "import opendatasets as od\n",
        "dataset_url= 'https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000'\n",
        "od.download('https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000')"
      ],
      "metadata": {
        "id": "ekTTyyMz089b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create function def"
      ],
      "metadata": {
        "id": "5ZoBC8qr5foU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**function for train test splits**"
      ],
      "metadata": {
        "id": "X_47Ykom5sEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define function for train test splits\n",
        "def train_test_splits(X, Y):\n",
        "    # Splitting into train and test set\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "    \n",
        "    # Prepare data for training and testing the model\n",
        "    train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  rotation_range = 10,\n",
        "                                  width_shift_range = 0.2,\n",
        "                                  height_shift_range = 0.2,\n",
        "                                  shear_range = 0.2,\n",
        "                                  horizontal_flip = True,\n",
        "                                  vertical_flip = True,\n",
        "                                  fill_mode = 'nearest')\n",
        "    train_datagen.fit(X_train)\n",
        "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "    test_datagen.fit(X_test)\n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "metadata": {
        "id": "iwJ7Gstb0_9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**function for Modeling**"
      ],
      "metadata": {
        "id": "i0iUVuoa55Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define function for create model\n",
        "def model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, kernel_size = (3,3), input_shape = (28, 28, 3), activation = 'relu', padding = 'same'))\n",
        "    model.add(MaxPool2D(pool_size = (2,2)))\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
        "    model.add(MaxPool2D(pool_size = (2,2), padding = 'same'))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
        "    model.add(MaxPool2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Conv2D(128, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
        "    model.add(MaxPool2D(pool_size = (2,2), padding = 'same'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "    model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "                 optimizer = optimizer,\n",
        "                  metrics = ['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model;"
      ],
      "metadata": {
        "id": "SL-jybJG6R02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**function for training model**"
      ],
      "metadata": {
        "id": "eikRPc3O595_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for training model\n",
        "def train_model(model, X_train, Y_train, EPOCHS=25):\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, \n",
        "                           mode='auto')\n",
        "                               \n",
        "    \n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
        "                              verbose=1, mode='auto')\n",
        "    \n",
        "    history = model.fit(X_train,\n",
        "                        Y_train,\n",
        "                        validation_split=0.2,\n",
        "                        batch_size = 64,\n",
        "                        epochs = EPOCHS,\n",
        "                        callbacks = [reduce_lr, early_stop])\n",
        "    return history"
      ],
      "metadata": {
        "id": "zicQtenV6TyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**function for test model**"
      ],
      "metadata": {
        "id": "inhxhQtn6B30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for model testing\n",
        "def test_model(model, X_test, Y_test):\n",
        "    model_acc = model.evaluate(X_test, Y_test, verbose=0)[1]\n",
        "    print(\"Test Accuracy: {:.3f}%\".format(model_acc * 100))\n",
        "    y_true = np.array(Y_test)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.array(list(map(lambda x: np.argmax(x), y_pred)))\n",
        "    clr = classification_report(y_true, y_pred, target_names=label_mapping.values())\n",
        "    print(clr)\n",
        "    \n",
        "    sample_data = X_test[:15]\n",
        "    plt.figure(figsize=(22, 12))\n",
        "    for i in range(15):\n",
        "        plt.subplot(3, 5, i + 1)\n",
        "        plt.imshow(sample_data[i])\n",
        "        plt.title(label_mapping[y_true[i][0]] + '|' + label_mapping[y_pred[i]])\n",
        "        plt.axis(\"off\")\n",
        "    plt.show() "
      ],
      "metadata": {
        "id": "ddC41sXs6X1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**function for plotting model accuracy and loss**"
      ],
      "metadata": {
        "id": "L-_FXwHb6Fad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for training curves plot\n",
        "def plot_model_training_curve(history):\n",
        "    fig = make_subplots(rows=1, cols=2, subplot_titles=['Model Accuracy', 'Model Loss'])\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            y=history.history['accuracy'], \n",
        "            name='train_acc'), \n",
        "        row=1, col=1)\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            y=history.history['val_accuracy'], \n",
        "            name='val_acc'), \n",
        "        row=1, col=1)\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            y=history.history['loss'], \n",
        "            name='train_loss'), \n",
        "        row=1, col=2)\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            y=history.history['val_loss'], \n",
        "            name='val_loss'), \n",
        "        row=1, col=2)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "Je8YO6z26aUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Understanding**\n"
      ],
      "metadata": {
        "id": "bfbKNu6J617B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory\n",
        "base_skin_dir = '/content/skin-cancer-mnist-ham10000'\n",
        "\n",
        "# Merging images from both folders HAM10000_images_part1.zip and HAM10000_images_part2.zip into one dictionary\n",
        "\n",
        "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
        "                     for x in glob(os.path.join(base_skin_dir,\"skin-cancer-mnist-ham10000/\", '*', '*.jpg'))}\n",
        "# create dictionary for type of skin cancer\n",
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi (nv)',\n",
        "    'mel': 'Melanoma (mel)',\n",
        "    'bkl': 'Benign keratosis-like lesions (bkl)',\n",
        "    'bcc': 'Basal cell carcinoma (bcc)',\n",
        "    'akiec': 'Actinic keratoses (akiec)',\n",
        "    'vasc': 'Vascular lesions (vasc)',\n",
        "    'df': 'Dermatofibroma (df)'\n",
        "}\n",
        "# create label mapping\n",
        "label_mapping = {\n",
        "    0: 'nv',\n",
        "    1: 'mel',\n",
        "    2: 'bkl',\n",
        "    3: 'bcc',\n",
        "    4: 'akiec',\n",
        "    5: 'vasc',\n",
        "    6: 'df'\n",
        "}\n",
        "reverse_label_mapping = dict((value, key) for key, value in label_mapping.items())"
      ],
      "metadata": {
        "id": "vq7IFf8v68U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the csv data\n",
        "data = pd.read_csv(os.path.join(base_skin_dir,\"skin-cancer-mnist-ham10000/\",'HAM10000_metadata.csv'))"
      ],
      "metadata": {
        "id": "XlCUWTY77EGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets see the sample of tile_df to look on newly made columns\n",
        "data.head()"
      ],
      "metadata": {
        "id": "tzuTNsmc7Fvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# more info about data \n",
        "data.describe(exclude=[np.number])"
      ],
      "metadata": {
        "id": "J3SoZQ5W7Hq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning**"
      ],
      "metadata": {
        "id": "psM0Vhgk7JDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking a null data\n",
        "data.isnull().any().sum()"
      ],
      "metadata": {
        "id": "Bv7l7bRF7IsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling null values\n",
        "data['age'].fillna(value=int(data['age'].mean()), inplace=True)\n",
        "# Converting dtype of age to int32\n",
        "data['age'] = data['age'].astype('int32')\n",
        "\n",
        "# Adding cell_type and image_path columns\n",
        "data['cell_type'] = data['dx'].map(lesion_type_dict.get)\n",
        "data['path'] = data['image_id'].map(imageid_path_dict.get)"
      ],
      "metadata": {
        "id": "mwkBvvyB7SEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check a data\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Okwf4YA37Tuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding image pixels\n",
        "data['image_pixel'] = data['path'].map(lambda x: np.asarray(Image.open(x).resize((28,28))))"
      ],
      "metadata": {
        "id": "34s5sbcp7V6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New updates of data\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "FibhXIvA7XHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preparation**"
      ],
      "metadata": {
        "id": "qLQHeWEi7-d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying 2 images for each label\n",
        "sample_data = data.groupby('dx').apply(lambda df: df.iloc[:2, [9, 7]])\n",
        "plt.figure(figsize=(22, 32))\n",
        "for i in range(14):\n",
        "    plt.subplot(7, 5, i + 1)\n",
        "    plt.imshow(np.squeeze(sample_data['image_pixel'][i]))\n",
        "    img_label = sample_data['cell_type'][i]\n",
        "    plt.title(img_label)\n",
        "    plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "mbe-FJy38Be-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'] = data['dx'].map(reverse_label_mapping.get)\n",
        "\n",
        "data = data.sort_values('label')\n",
        "data = data.reset_index()"
      ],
      "metadata": {
        "id": "D7z9uAIA8Cxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "frames = [data]\n",
        "for i in [4,4,11,17,45,52]:\n",
        "    counter+=1\n",
        "    index = data[data['label'] == counter].index.values\n",
        "    df_index = data.iloc[int(min(index)):int(max(index)+1)]\n",
        "    df_index = df_index.append([df_index]*i, ignore_index = True)\n",
        "    frames.append(df_index)"
      ],
      "metadata": {
        "id": "4ZMxRCaL8E0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(frames)"
      ],
      "metadata": {
        "id": "ODEYLvS38GCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = pd.concat(frames)"
      ],
      "metadata": {
        "id": "QrMbwdeI8HLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)\n",
        "print(final_data.shape)"
      ],
      "metadata": {
        "id": "6RDBQVI-8Ihs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ORIGINAL DATA\n",
        "# Converting image pixel columnm into required format\n",
        "X_orig = data['image_pixel'].to_numpy()\n",
        "X_orig = np.stack(X_orig, axis=0)\n",
        "Y_orig = np.array(data.iloc[:, -1:])\n",
        "print(X_orig.shape)\n",
        "print(Y_orig.shape)"
      ],
      "metadata": {
        "id": "8_Hylw_p8KEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUGMENTED DATA\n",
        "# Converting image pixel columnm into required format\n",
        "X_aug = final_data['image_pixel'].to_numpy()\n",
        "X_aug = np.stack(X_aug, axis=0)\n",
        "Y_aug = np.array(final_data.iloc[:, -1:])\n",
        "print(X_aug.shape)\n",
        "print(Y_aug.shape)"
      ],
      "metadata": {
        "id": "k4AyO1Vx8LUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Original Dataset\n",
        "X_train_orig, X_test_orig, Y_train_orig, Y_test_orig = train_test_splits(X_orig, Y_orig)"
      ],
      "metadata": {
        "id": "Fyd42f8K8Mts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Augmentation Dataset\n",
        "X_train_aug, X_test_aug, Y_train_aug, Y_test_aug = train_test_splits(X_aug, Y_aug)"
      ],
      "metadata": {
        "id": "AbE9tPQA8NOq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}